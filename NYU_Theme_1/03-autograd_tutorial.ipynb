{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "from torch import optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grad_fn.next_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1,2], [3,4]], dtype=torch.float32, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AccumulateGrad at 0x7efd385be160>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn.next_functions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y * y * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  3.],\n",
       "        [12., 27.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<AccumulateGrad at 0x7efd385be160>, 0), (None, 0))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad_fn.next_functions[0][0].next_functions[0][0].next_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MeanBackward0 at 0x7efd385be550>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qnarik/miniconda3/envs/exps/lib/python3.9/site-packages/torch/autograd/__init__.py:197: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "a.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MeanBackward0 at 0x7efd385be550>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# backward([values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1289,  0.2762, -0.9459], requires_grad=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.randn(3, requires_grad=True)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = v * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9970)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.data.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9970)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(w).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9970, grad_fn=<NormBackward1>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while w.data.norm() < 1000:\n",
    "    w *= 2\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1155.9792,  282.8611, -968.6234], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if one of multipliers has no req_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "w.backward(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(1., n + 1, requires_grad=True)\n",
    "w = torch.ones(n, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3.], requires_grad=True),\n",
       " tensor([1., 1., 1.], requires_grad=True))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6., grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.]) tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad, w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(1., n+1)\n",
    "w = torch.ones(n, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3.]), tensor([1., 1., 1.], requires_grad=True))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 0), (<AccumulateGrad at 0x7f0e125f4d00>, 0))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad_fn.next_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([1., 2., 3.]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad, w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(1., n+1, requires_grad=True)\n",
    "w = torch.ones(n, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3.], requires_grad=True),\n",
       " tensor([1., 1., 1.], requires_grad=True))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = x @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_314761/148511205.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/exps/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/envs/exps/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2618, 0.5236, 0.7854, 1.0472, 1.3090, 1.5708, 1.8326, 2.0944,\n",
       "        2.3562, 2.6180, 2.8798, 3.1416, 3.4034, 3.6652, 3.9270, 4.1888, 4.4506,\n",
       "        4.7124, 4.9742, 5.2360, 5.4978, 5.7596, 6.0214, 6.2832],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.linspace(0., 2. * math.pi, 25, requires_grad=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000e+00,  2.5882e-01,  5.0000e-01,  7.0711e-01,  8.6603e-01,\n",
       "         9.6593e-01,  1.0000e+00,  9.6593e-01,  8.6603e-01,  7.0711e-01,\n",
       "         5.0000e-01,  2.5882e-01, -8.7423e-08, -2.5882e-01, -5.0000e-01,\n",
       "        -7.0711e-01, -8.6603e-01, -9.6593e-01, -1.0000e+00, -9.6593e-01,\n",
       "        -8.6603e-01, -7.0711e-01, -5.0000e-01, -2.5882e-01,  1.7485e-07],\n",
       "       grad_fn=<SinBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.sin(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_438628/3577467735.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.axhline(c=\"gray\")\n",
    "plt.axvline(c=\"gray\")\n",
    "plt.plot(a.detach().numpy(), b.detach().numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000e+00,  5.1764e-01,  1.0000e+00,  1.4142e+00,  1.7321e+00,\n",
       "         1.9319e+00,  2.0000e+00,  1.9319e+00,  1.7321e+00,  1.4142e+00,\n",
       "         1.0000e+00,  5.1764e-01, -1.7485e-07, -5.1764e-01, -1.0000e+00,\n",
       "        -1.4142e+00, -1.7321e+00, -1.9319e+00, -2.0000e+00, -1.9319e+00,\n",
       "        -1.7321e+00, -1.4142e+00, -1.0000e+00, -5.1764e-01,  3.4969e-07],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 2 * b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000e+00,  1.5176e+00,  2.0000e+00,  2.4142e+00,  2.7321e+00,\n",
       "         2.9319e+00,  3.0000e+00,  2.9319e+00,  2.7321e+00,  2.4142e+00,\n",
       "         2.0000e+00,  1.5176e+00,  1.0000e+00,  4.8236e-01, -3.5763e-07,\n",
       "        -4.1421e-01, -7.3205e-01, -9.3185e-01, -1.0000e+00, -9.3185e-01,\n",
       "        -7.3205e-01, -4.1421e-01,  4.7684e-07,  4.8236e-01,  1.0000e+00],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = c + 1\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = d.sum()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SinBackward0 at 0x7efd3606b1f0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.grad_fn.next_functions[0][0]\n",
    "d.grad_fn.next_functions[0][0].next_functions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qnarik/miniconda3/envs/exps/lib/python3.9/site-packages/torch/autograd/__init__.py:197: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0000e+00,  1.9319e+00,  1.7321e+00,  1.4142e+00,  1.0000e+00,\n",
       "         5.1764e-01, -8.7423e-08, -5.1764e-01, -1.0000e+00, -1.4142e+00,\n",
       "        -1.7321e+00, -1.9319e+00, -2.0000e+00, -1.9319e+00, -1.7321e+00,\n",
       "        -1.4142e+00, -1.0000e+00, -5.1764e-01,  2.3850e-08,  5.1764e-01,\n",
       "         1.0000e+00,  1.4142e+00,  1.7321e+00,  1.9319e+00,  2.0000e+00])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efd36052cd0>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a.detach().numpy(), a.grad.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "DIM_IN = 1000\n",
    "HIDDEN_SIZE = 100\n",
    "DIM_OUT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyModel(nn.Module):\n",
    "    def __init__(self,\n",
    "        in_features: int = 1000,\n",
    "        out_features: int = 10,\n",
    "        hidden_dim: int = 100\n",
    "    ) -> None:\n",
    "        super().__init__() # Initialize self._modules as OrderedDict\n",
    "\n",
    "        self.l1 = nn.Linear(in_features, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_dim, out_features)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.l1(x)\n",
    "        x = self. relu(x)\n",
    "        x = self.l2(x)\n",
    "\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(BATCH_SIZE, DIM_IN)\n",
    "y = torch.randn(BATCH_SIZE, DIM_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TinyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyModel(\n",
       "  (l1): Linear(in_features=1000, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (l2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.l2.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.l2.weight.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.l1.weight.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (y - out).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8720, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.l2.weight.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0062,  0.0060,  0.0001,  ..., -0.0007, -0.0071,  0.0120],\n",
       "        [-0.0061,  0.0018, -0.0209,  ...,  0.0012, -0.0146, -0.0132],\n",
       "        [-0.0038, -0.0094, -0.0126,  ...,  0.0004,  0.0009, -0.0035],\n",
       "        ...,\n",
       "        [ 0.0016,  0.0071,  0.0130,  ...,  0.0150,  0.0006, -0.0017],\n",
       "        [ 0.0076,  0.0125, -0.0120,  ...,  0.0037, -0.0204,  0.0040],\n",
       "        [-0.0005, -0.0004,  0.0030,  ...,  0.0016, -0.0016,  0.0002]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.l1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0160,  0.0163,  0.0109,  ...,  0.0181,  0.0302,  0.0133],\n",
       "        [ 0.0067, -0.0003, -0.0043,  ...,  0.0042, -0.0165, -0.0105],\n",
       "        [-0.0279, -0.0133, -0.0035,  ..., -0.0044,  0.0195, -0.0234],\n",
       "        ...,\n",
       "        [ 0.0286, -0.0316, -0.0075,  ...,  0.0006, -0.0174, -0.0169],\n",
       "        [-0.0247,  0.0101, -0.0183,  ...,  0.0117,  0.0128, -0.0246],\n",
       "        [ 0.0064, -0.0293,  0.0026,  ..., -0.0150, -0.0214, -0.0211]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.l1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0141,  0.0145,  0.0109,  ...,  0.0183,  0.0323,  0.0097],\n",
       "        [ 0.0085, -0.0009,  0.0020,  ...,  0.0039, -0.0121, -0.0065],\n",
       "        [-0.0268, -0.0105,  0.0003,  ..., -0.0045,  0.0193, -0.0223],\n",
       "        ...,\n",
       "        [ 0.0281, -0.0337, -0.0114,  ..., -0.0039, -0.0175, -0.0164],\n",
       "        [-0.0270,  0.0063, -0.0147,  ...,  0.0106,  0.0189, -0.0258],\n",
       "        [ 0.0065, -0.0292,  0.0017,  ..., -0.0155, -0.0209, -0.0211]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.l1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.l1.weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning Autograd Off and On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary switch off\n",
    "a = torch.randn(2,3, requires_grad=True)\n",
    "b = torch.randn(2,3, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4025, -0.4631, -1.2466],\n",
       "        [ 1.7495,  0.0537, -0.3402]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = a+b\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    c2 = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4025, -0.4631, -1.2466],\n",
       "        [ 1.7495,  0.0537, -0.3402]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tensors(x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
    "    return x1 + x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def add_tensors_with_dec(x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
    "    return x1 + x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4025, -0.4631, -1.2466],\n",
       "        [ 1.7495,  0.0537, -0.3402]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_tensors(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4025, -0.4631, -1.2466],\n",
       "        [ 1.7495,  0.0537, -0.3402]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_tensors_with_dec(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1818, 0.2574, 0.0108, 0.9572, 0.4731], requires_grad=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1818, 0.2574, 0.0108, 0.9572, 0.4731])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.detach()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2574, 0.0108, 0.9572, 0.4731])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0] = 0\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2574, 0.0108, 0.9572, 0.4731], requires_grad=True)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detach return link\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inplace operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0526, 1.1053, 1.1579, 1.2105, 1.2632, 1.3158, 1.3684, 1.4211,\n",
       "        1.4737, 1.5263, 1.5789, 1.6316, 1.6842, 1.7368, 1.7895, 1.8421, 1.8947,\n",
       "        1.9474, 2.0000], requires_grad=True)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.linspace(1.,2.,20, requires_grad=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_438628/809176640.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: a leaf Variable that requires grad is being used in an in-place operation."
     ]
    }
   ],
   "source": [
    "a.sin_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd Profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 3, requires_grad=True)\n",
    "y = torch.randn(2, 3, requires_grad=True)\n",
    "z = torch.ones(2,3, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-01-20 02:12:53 438628:438628 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-01-20 02:12:53 438628:438628 ActivityProfilerController.cpp:300] Completed Stage: Collection\n"
     ]
    }
   ],
   "source": [
    "with torch.autograd.profiler.profile(use_cuda=False) as prf:\n",
    "    for _ in range(1000):\n",
    "        z = (z / x) * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "    aten::div        51.35%       1.355ms        51.35%       1.355ms       1.355us          1000  \n",
      "    aten::mul        48.65%       1.284ms        48.65%       1.284ms       1.284us          1000  \n",
      "-------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.639ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prf.key_averages().table(sort_by='self_cpu_time_total'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Autograd Detail and the High-Level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 503.9240, -882.2154,   73.5717], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward(torch.tensor([0.1, 0.01, 0.0001]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.]]),\n",
       " tensor([[1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.]]))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.functional.jacobian(torch.add, (y, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking local gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed: int = 2):\n",
    "    os.environ['PYTHONHASHSEDD'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(2)\n",
    "\n",
    "f1 = nn.Linear(2,2)\n",
    "act = nn.Sigmoid()\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.1622, -0.1683],\n",
       "         [ 0.1939, -0.0361]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3021, 0.1683], requires_grad=True))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.weight, f1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.eye(2,2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = f1(x)\n",
    "out1.retain_grad()\n",
    "out2 = act(out1)\n",
    "out2.retain_grad()\n",
    "loss = loss_fn(out2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7041, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0560, -0.0137],\n",
       "        [-0.0286,  0.0501]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1622, -0.1683],\n",
       "        [ 0.1939, -0.0361]], requires_grad=True)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no updates\n",
    "f1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1115,  0.1369],\n",
       "        [ 0.1445, -0.1086]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dL/dout1\n",
    "out1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4513,  0.5524],\n",
       "        [ 0.5926, -0.4420]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dL/dout2\n",
    "out2.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "want local gradients like dout1/dout2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18045/201696242.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/exps/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/envs/exps/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "out1.backward(out2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out2.grad.zero_()\n",
    "out1.grad.zero_()\n",
    "out1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out2.grad.detach_()\n",
    "out1.grad.detach_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4513,  0.5524],\n",
       "        [ 0.5926, -0.4420]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18045/1027175335.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/exps/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/envs/exps/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "out1.backward(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5540, 0.5474],\n",
       "        [0.5781, 0.5656]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# local grads\n",
    "out1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('exps')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1bd9a7837112e3c677dc6441e3382ca35d49b41dec56a9c5676f1bd554345e28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
